# ================================================================
# ğŸ“š DNN ê¸°ë°˜ ëª¨í„° Torque Curve ì˜ˆì¸¡ (Torque Only, 18 outputs)
# - ì…ë ¥(11ê°œ ì„¤ê³„ë³€ìˆ˜) -> 1000~18000rpm í† í¬(18ê°œ) ì˜ˆì¸¡
# - ë³€ìˆ˜ëª… í†µì¼: X_cols, y_cols
# - ë…¼ë¬¸ìš© ì§€í‘œ ì €ì¥: RMSE/MAE/R2 (RPMë³„ + í‰ê· ) -> CSV/JSON
# - í•™ìŠµ ê³¡ì„ /ì”ì°¨/Actual-vs-Pred ì‚°ì ë„ ì €ì¥ + í°íŠ¸ í¬ê¸° ì¡°ì ˆ
# - Train lossê°€ ë” í° í˜„ìƒ(Dropout ë“±) ì ê²€ìš©: eval ëª¨ë“œì—ì„œ train/val loss ì¬ê³„ì‚°
# - GPU ì˜µì…˜ í¬í•¨
# - ìŠ¤ì¼€ì¼ëŸ¬ ëˆ„ìˆ˜ ë°©ì§€: train setìœ¼ë¡œë§Œ fit (ë…¼ë¬¸ ì¹œí™”ì )
# ================================================================

import os
import json
from io import StringIO

import numpy as np
import pandas as pd
import joblib

import torch
import torch.nn as nn
import torch.optim as optim

from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt


# ================================================================
# 0) ì‚¬ìš©ì ì„¤ì • (ì—¬ê¸°ë§Œ ë§Œì§€ë©´ ë¨)
# ================================================================
DATA_PATH = "data/a.csv"

# GPU ì‚¬ìš© ì—¬ë¶€ (CUDA ìˆìœ¼ë©´ ìë™ ì‚¬ìš©)
USE_GPU = True

# í•™ìŠµ ì„¤ì •
NUM_EPOCHS = 2000
PATIENCE = 50
LR = 1e-3
WEIGHT_DECAY = 1e-5

# K-Fold (ì‹œê°„ ë§ì´ ê±¸ë¦¼)
USE_CV = True
N_FOLDS = 5
CV_EPOCHS = 200

# ê·¸ë˜í”„ í°íŠ¸/í•´ìƒë„ ì„¤ì •
PLOT_FONTS = {
    "title": 18,
    "label":18,
    "tick": 18,
    "legend": 18,
}
PLOT_DPI = 300

# ëŒ€í‘œ RPM scatter (ë…¼ë¬¸ìš©)
REP_RPMS = [3000, 9000, 15000, 18000]

# ì¬í˜„ì„±
SEED = 42


# ================================================================
# 1) ê¸°ë³¸ ì„¸íŒ… + ì¶œë ¥ í´ë”
# ================================================================
np.random.seed(SEED)
torch.manual_seed(SEED)

RPMS = np.arange(1000, 18001, 1000)  # 1000~18000 step 1000 => 18ê°œ
N_SPEEDS = len(RPMS)

OUT_DIR_MACHINE = "machine"
OUT_DIR_GRAPH = "graph"
OUT_DIR_RESID = "residual_plots"
os.makedirs(OUT_DIR_MACHINE, exist_ok=True)
os.makedirs(OUT_DIR_GRAPH, exist_ok=True)
os.makedirs(OUT_DIR_RESID, exist_ok=True)

device = torch.device("cuda" if (USE_GPU and torch.cuda.is_available()) else "cpu")
print(f"\nğŸ§  Device: {device} (USE_GPU={USE_GPU})")


# ================================================================
# 2) ë°ì´í„° ë¡œë”© ë° ì •ì œ
# ================================================================
try:
    with open(DATA_PATH, "r", encoding="utf-8-sig") as f:
        text = f.read()
except FileNotFoundError:
    raise FileNotFoundError(f"âŒ ì˜¤ë¥˜: '{DATA_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# íƒ­ì´ ë¬¸ìì—´ "\\t"ë¡œ ë“¤ì–´ì˜¨ ì¼€ì´ìŠ¤ ëŒ€ì‘ + ë”°ì˜´í‘œ ì œê±°
text = text.replace('"', "").replace("\\t", "\t")

df = pd.read_csv(StringIO(text), sep="\t")
df.columns = df.columns.str.replace("#", "", regex=False).str.strip()

print("\nğŸ“Š ë°ì´í„° ë¡œë”© ì™„ë£Œ")
print(f"   ì „ì²´ í–‰/ì—´: {df.shape}")


# ================================================================
# 3) ì…ë ¥/ì¶œë ¥ ì»¬ëŸ¼ ì •ì˜ (ë³€ìˆ˜ëª… í†µì¼!)
# ================================================================
X_cols = [
    "L1_Pole_V_Angle",
    "L1_Bridge_Thickness",
    "DC_Link_Voltage",
    "Airgap",
    "Turns",
    "Active_Length",
    "Tooth_Width_Ratio",
    "Stator_Bore_Ratio",
    "Slot_Depth_Ratio",
    "Max_Phase_Current",
    "L1_Magnet_Bar_Width_Ratio",
]

# Torque only targets (18ê°œ)
y_cols = [f"peak_Shaft_Torque_{rpm}rpm" for rpm in RPMS]

print("\nğŸ“Œ ì»¬ëŸ¼ ì •ë³´")
print(f"   ì…ë ¥ X: {len(X_cols)}ê°œ")
print(f"   ì¶œë ¥ y (Torque only): {len(y_cols)}ê°œ")


# ================================================================
# 4) ì»¬ëŸ¼ ì¡´ì¬ ì²´í¬ + ìœ íš¨ ë°ì´í„° í•„í„°ë§ + ê²°ì¸¡ ì²˜ë¦¬
# ================================================================
missing_x = [c for c in X_cols if c not in df.columns]
missing_y = [c for c in y_cols if c not in df.columns]
if missing_x or missing_y:
    msg = "âŒ ë°ì´í„° ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n"
    if missing_x:
        msg += f"   ëˆ„ë½ëœ ì…ë ¥ ì»¬ëŸ¼: {missing_x}\n"
    if missing_y:
        msg += f"   ëˆ„ë½ëœ ì¶œë ¥ ì»¬ëŸ¼: {missing_y}\n"
    raise KeyError(msg)

# ì¶œë ¥ ì¤‘ í•˜ë‚˜ë¼ë„ 0ì´ë©´(ë˜ëŠ” NaNì„ 0ìœ¼ë¡œ ë³´ê³ ) ì œê±° -> í•´ì„ ì‹¤íŒ¨ ì œê±°
valid = np.ones(len(df), dtype=bool)
for col in y_cols:
    valid &= (df[col].fillna(0) != 0)

removed = len(df) - valid.sum()
df = df[valid].copy()

print("\nğŸ§¹ ë¬´íš¨ ë°ì´í„° ì œê±°")
print(f"   ì œê±°: {removed}ê°œ -> ë‚¨ìŒ: {len(df)}ê°œ")

# X, y ë¶„ë¦¬
X = df[X_cols].copy()
y = df[y_cols].copy()

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬(ë‚¨ì•„ìˆë‹¤ë©´ í‰ê·  ëŒ€ì²´)
if X.isnull().values.any():
    print("âš ï¸ ì…ë ¥ Xì— NaN ë°œê²¬ -> í‰ê· ìœ¼ë¡œ ëŒ€ì²´")
    X = X.fillna(X.mean())

if y.isnull().values.any():
    print("âš ï¸ ì¶œë ¥ yì— NaN ë°œê²¬ -> í‰ê· ìœ¼ë¡œ ëŒ€ì²´")
    y = y.fillna(y.mean())


# ================================================================
# 5) Train/Test Split (ìŠ¤ì¼€ì¼ëŸ¬ ëˆ„ìˆ˜ ë°©ì§€: split í›„ trainìœ¼ë¡œë§Œ fit)
# ================================================================
X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
    X, y, test_size=0.2, random_state=SEED
)

x_scaler = StandardScaler().fit(X_train_raw)
y_scaler = StandardScaler().fit(y_train_raw)

X_train = x_scaler.transform(X_train_raw)
X_test = x_scaler.transform(X_test_raw)
y_train = y_scaler.transform(y_train_raw)
y_test = y_scaler.transform(y_test_raw)

joblib.dump(x_scaler, os.path.join(OUT_DIR_MACHINE, "x_scaler_torque.gz"))
joblib.dump(y_scaler, os.path.join(OUT_DIR_MACHINE, "y_scaler_torque.gz"))
print("\nâœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ (ëˆ„ìˆ˜ ë°©ì§€: trainìœ¼ë¡œë§Œ fit)")
print("   machine/x_scaler_torque.gz")
print("   machine/y_scaler_torque.gz")

# Torch tensor ë³€í™˜ + device ì´ë™
X_train_t = torch.tensor(X_train, dtype=torch.float32, device=device)
y_train_t = torch.tensor(y_train, dtype=torch.float32, device=device)
X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)
y_test_t = torch.tensor(y_test, dtype=torch.float32, device=device)

print("\nğŸ“¦ ë°ì´í„° ë¶„í• ")
print(f"   í•™ìŠµ: {len(X_train)}ê°œ")
print(f"   ê²€ì¦: {len(X_test)}ê°œ")


# ================================================================
# 6) ëª¨ë¸ ì •ì˜
# ================================================================
class MultiOutputNN_Regulated(nn.Module):
    def __init__(self, in_dim: int, out_dim: int, dropout_p: float = 0.2):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, 128),
            nn.ReLU(),
            nn.Dropout(dropout_p),

            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(dropout_p),

            nn.Linear(64, out_dim),
        )

    def forward(self, x):
        return self.net(x)


model = MultiOutputNN_Regulated(in_dim=len(X_cols), out_dim=len(y_cols)).to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

print("\nğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°")
print(f"   in_dim={len(X_cols)}, out_dim={len(y_cols)} (Torque only)")


# ================================================================
# 7) (ì„ íƒ) K-Fold CV (ëˆ„ìˆ˜ ë°©ì§€ ë²„ì „)
# ================================================================
if USE_CV:
    print(f"\nğŸ” K-Fold ì‹œì‘: {N_FOLDS} folds, foldë‹¹ ìµœëŒ€ {CV_EPOCHS} epochs")
    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)

    cv_rmse_means, cv_r2_means = [], []

    # KFoldëŠ” ì›ë³¸ X,y(DataFrame) ê¸°ì¤€ìœ¼ë¡œ split í›„ foldë§ˆë‹¤ ìŠ¤ì¼€ì¼ëŸ¬ fit
    for fold, (tr_idx, va_idx) in enumerate(kf.split(X)):
        X_tr_raw, X_va_raw = X.iloc[tr_idx], X.iloc[va_idx]
        y_tr_raw, y_va_raw = y.iloc[tr_idx], y.iloc[va_idx]

        x_sc = StandardScaler().fit(X_tr_raw)
        y_sc = StandardScaler().fit(y_tr_raw)

        X_tr = x_sc.transform(X_tr_raw)
        X_va = x_sc.transform(X_va_raw)
        y_tr = y_sc.transform(y_tr_raw)
        y_va = y_sc.transform(y_va_raw)

        X_tr_t = torch.tensor(X_tr, dtype=torch.float32, device=device)
        y_tr_t = torch.tensor(y_tr, dtype=torch.float32, device=device)
        X_va_t = torch.tensor(X_va, dtype=torch.float32, device=device)
        y_va_t = torch.tensor(y_va, dtype=torch.float32, device=device)

        m = MultiOutputNN_Regulated(len(X_cols), len(y_cols)).to(device)
        opt = optim.Adam(m.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

        best = float("inf")
        patience_cv = 20
        pc = 0
        best_state = None

        for epoch in range(CV_EPOCHS):
            m.train()
            opt.zero_grad()
            out = m(X_tr_t)
            loss = criterion(out, y_tr_t)
            loss.backward()
            opt.step()

            m.eval()
            with torch.no_grad():
                va_out = m(X_va_t)
                va_loss = criterion(va_out, y_va_t)

            if va_loss.item() < best:
                best = va_loss.item()
                pc = 0
                best_state = {k: v.detach().cpu() for k, v in m.state_dict().items()}
            else:
                pc += 1
                if pc >= patience_cv:
                    break

        if best_state is not None:
            m.load_state_dict({k: v.to(device) for k, v in best_state.items()})

        m.eval()
        with torch.no_grad():
            pred_va_s = m(X_va_t).detach().cpu().numpy()

        pred_va = y_sc.inverse_transform(pred_va_s)
        y_va_true = y_va_raw.values

        rmse_each = np.sqrt(mean_squared_error(y_va_true, pred_va, multioutput="raw_values"))
        r2_each = r2_score(y_va_true, pred_va, multioutput="raw_values")

        cv_rmse_means.append(float(np.mean(rmse_each)))
        cv_r2_means.append(float(np.mean(r2_each)))

        print(f"Fold {fold+1}: mean RMSE={np.mean(rmse_each):.4f}, mean R2={np.mean(r2_each):.4f}")

    print("\nâœ… CV í‰ê· ")
    print(f"   RMSE={np.mean(cv_rmse_means):.4f}")
    print(f"   R2  ={np.mean(cv_r2_means):.4f}")


# ================================================================
# 8) í•™ìŠµ (Early Stopping)
# ================================================================
best_val = float("inf")
pc = 0
history = {"train_loss": [], "val_loss": []}
best_path = os.path.join(OUT_DIR_MACHINE, "motor_model_best_temp_torque.pth")

print("\n" + "=" * 60)
print("ğŸš€ í•™ìŠµ ì‹œì‘ (Torque only, Early Stopping)")
print("=" * 60)

for epoch in range(NUM_EPOCHS):
    # ---- train ----
    model.train()  # Dropout ON
    optimizer.zero_grad()
    pred = model(X_train_t)
    loss = criterion(pred, y_train_t)
    loss.backward()
    optimizer.step()

    # ---- val ----
    model.eval()   # Dropout OFF
    with torch.no_grad():
        val_pred = model(X_test_t)
        val_loss = criterion(val_pred, y_test_t)

    history["train_loss"].append(loss.item())
    history["val_loss"].append(val_loss.item())

    # early stopping
    if val_loss.item() < best_val:
        best_val = val_loss.item()
        pc = 0
        torch.save(model.state_dict(), best_path)
    else:
        pc += 1
        if pc >= PATIENCE:
            print(f"\nğŸ›‘ Early Stopping at epoch {epoch+1}")
            break

    if (epoch + 1) % 100 == 0:
        print(f"[{epoch+1:4d}] train={loss.item():.6f} | val={val_loss.item():.6f}")

# ìµœì  ê°€ì¤‘ì¹˜ ë¡œë“œ
model.load_state_dict(torch.load(best_path, map_location=device))
try:
    os.remove(best_path)
except Exception:
    pass
print("\nâœ… ìµœì  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")


# ================================================================
# 9) (ì¤‘ìš”) Dropout ì˜í–¥ ì ê²€: ê°™ì€ ëª¨ë“œ(eval)ì—ì„œ train/val loss ì¬ì¸¡ì •
# ================================================================
model.eval()
with torch.no_grad():
    train_eval_loss = criterion(model(X_train_t), y_train_t).item()
    val_eval_loss = criterion(model(X_test_t), y_test_t).item()

print("\nğŸ§ª Loss check (same mode: eval)")
print(f"   Train(eval) loss: {train_eval_loss:.6f}")
print(f"   Val  (eval) loss: {val_eval_loss:.6f}")
print("   â€» train(loss) > val(loss)ê°€ Dropout ë•Œë¬¸ì¸ì§€ íŒë‹¨í•  ë•Œ ì´ ê°’ì´ ì¤‘ìš”í•¨")


# ================================================================
# 10) í•™ìŠµ ê³¡ì„  ì €ì¥ (í°íŠ¸ í¬ê¸° ì§€ì •)
# ================================================================
plt.figure(figsize=(12, 6))
plt.plot(history["train_loss"], label="Training Loss (train mode)", linewidth=2, alpha=0.85)
plt.plot(history["val_loss"], label="Validation Loss (eval mode)", linewidth=2, alpha=0.85, linestyle="--")
plt.yscale("log")

plt.title("Training Convergence (MSE, log scale)", fontsize=PLOT_FONTS["title"])
plt.xlabel("Epoch", fontsize=PLOT_FONTS["label"])
plt.ylabel("Loss", fontsize=PLOT_FONTS["label"])
plt.xticks(fontsize=PLOT_FONTS["tick"])
plt.yticks(fontsize=PLOT_FONTS["tick"])
plt.grid(alpha=0.35)
plt.legend(fontsize=PLOT_FONTS["legend"])
plt.tight_layout()

lc_path = os.path.join(OUT_DIR_GRAPH, "learning_curve_torque.png")
plt.savefig(lc_path, dpi=PLOT_DPI)
plt.close()
print(f"\nğŸ“ˆ í•™ìŠµ ê³¡ì„  ì €ì¥: {lc_path}")


# ================================================================
# 11) í‰ê°€: RMSE/R2/MAE ì €ì¥ + residual plots (Torque only)
# ================================================================
model.eval()
with torch.no_grad():
    preds_scaled = model(X_test_t).detach().cpu().numpy()

preds = y_scaler.inverse_transform(preds_scaled)
y_true = y_scaler.inverse_transform(y_test)  # y_testëŠ” numpy array

residuals = y_true - preds  # (n_samples, 18)

rmse_each = np.sqrt(mean_squared_error(y_true, preds, multioutput="raw_values"))  # (18,)
r2_each = r2_score(y_true, preds, multioutput="raw_values")                       # (18,)
mae_each = np.mean(np.abs(y_true - preds), axis=0)                                # (18,)

mean_rmse = float(np.mean(rmse_each))
mean_mae = float(np.mean(mae_each))
mean_r2 = float(np.mean(r2_each))

print("\n" + "=" * 60)
print("ğŸ“Š ëª¨ë¸ í‰ê°€ (Torque only)")
print("=" * 60)
print(f"í‰ê·  RÂ²  : {mean_r2:.4f}")
print(f"í‰ê·  RMSE: {mean_rmse:.4f} Nm")
print(f"í‰ê·  MAE : {mean_mae:.4f} Nm\n")

print("-" * 64)
print(f"{'RPM':>6s} | {'RÂ²':>8s} | {'RMSE(Nm)':>10s} | {'MAE(Nm)':>10s}")
print("-" * 64)
for i, rpm in enumerate(RPMS):
    print(f"{rpm:>6d} | {r2_each[i]:>8.4f} | {rmse_each[i]:>10.4f} | {mae_each[i]:>10.4f}")


# ---- ë…¼ë¬¸ìš© ì„±ëŠ¥ì§€í‘œ CSV ì €ì¥ (RPMë³„ + í‰ê·  í–‰) ----
metrics_df = pd.DataFrame({
    "rpm": RPMS,
    "rmse_Nm": rmse_each,
    "mae_Nm": mae_each,
    "r2": r2_each,
})
metrics_mean = pd.DataFrame([{
    "rpm": "MEAN",
    "rmse_Nm": mean_rmse,
    "mae_Nm": mean_mae,
    "r2": mean_r2,
}])
metrics_df_out = pd.concat([metrics_df, metrics_mean], ignore_index=True)

metrics_csv_path = os.path.join(OUT_DIR_MACHINE, "metrics_torque.csv")
metrics_df_out.to_csv(metrics_csv_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ“„ ì„±ëŠ¥ ì§€í‘œ CSV ì €ì¥: {metrics_csv_path}")

# ---- ë…¼ë¬¸/ìë™í™”ìš© JSON ì €ì¥ ----
metrics_json_path = os.path.join(OUT_DIR_MACHINE, "metrics_torque.json")
with open(metrics_json_path, "w", encoding="utf-8") as f:
    json.dump({
        "mean_rmse_Nm": mean_rmse,
        "mean_mae_Nm": mean_mae,
        "mean_r2": mean_r2,
        "train_eval_loss": float(train_eval_loss),
        "val_eval_loss": float(val_eval_loss),
        "per_rpm": metrics_df.to_dict(orient="records"),
        "config": {
            "DATA_PATH": DATA_PATH,
            "USE_GPU": USE_GPU,
            "device": str(device),
            "NUM_EPOCHS": NUM_EPOCHS,
            "PATIENCE": PATIENCE,
            "LR": LR,
            "WEIGHT_DECAY": WEIGHT_DECAY,
            "X_cols": X_cols,
            "y_cols": y_cols,
        }
    }, f, ensure_ascii=False, indent=2)
print(f"ğŸ§¾ ì„±ëŠ¥ ì§€í‘œ JSON ì €ì¥: {metrics_json_path}")


# ================================================================
# 12) Residual plots ì €ì¥
# ================================================================
# ì „ì²´ residual histogram
plt.figure(figsize=(10, 4))
plt.hist(residuals.flatten(), bins=80, alpha=0.85)
plt.title("Residuals Distribution (Torque only, all outputs)", fontsize=PLOT_FONTS["title"])
plt.xlabel("Actual - Predicted (Nm)", fontsize=PLOT_FONTS["label"])
plt.ylabel("Count", fontsize=PLOT_FONTS["label"])
plt.xticks(fontsize=PLOT_FONTS["tick"])
plt.yticks(fontsize=PLOT_FONTS["tick"])
plt.grid(alpha=0.25)
plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR_RESID, "residuals_hist_all_torque.png"), dpi=PLOT_DPI)
plt.close()

# rpmë³„ residual scatter
for i, rpm in enumerate(RPMS):
    x = preds[:, i]
    y_r = residuals[:, i]

    plt.figure(figsize=(6, 4))
    plt.scatter(x, y_r, s=12, alpha=0.6)
    plt.hlines(0, xmin=x.min(), xmax=x.max(), colors="r", linestyles="--", linewidth=1)
    plt.title(f"Torque Residuals @ {rpm} rpm", fontsize=PLOT_FONTS["title"])
    plt.xlabel("Predicted Torque (Nm)", fontsize=PLOT_FONTS["label"])
    plt.ylabel("Actual - Predicted (Nm)", fontsize=PLOT_FONTS["label"])
    plt.xticks(fontsize=PLOT_FONTS["tick"])
    plt.yticks(fontsize=PLOT_FONTS["tick"])
    plt.grid(alpha=0.35)
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR_RESID, f"residual_torque_{rpm}rpm.png"), dpi=PLOT_DPI)
    plt.close()

print(f"\nâœ… Residual plots ì €ì¥ ì™„ë£Œ: {OUT_DIR_RESID}/")


# ================================================================
# 13) ë…¼ë¬¸ìš© Actual vs Predicted scatter (ëŒ€í‘œ RPM)
# ================================================================
for r in REP_RPMS:
    if r not in RPMS:
        continue
    idx = int(np.where(RPMS == r)[0][0])

    plt.figure(figsize=(5.5, 5))
    plt.scatter(y_true[:, idx], preds[:, idx], s=12, alpha=0.55)

    mn = min(y_true[:, idx].min(), preds[:, idx].min())
    mx = max(y_true[:, idx].max(), preds[:, idx].max())
    plt.plot([mn, mx], [mn, mx], linestyle="--", linewidth=1)

    plt.title(f"Actual vs Predicted Torque @ {r} rpm", fontsize=PLOT_FONTS["title"])
    plt.xlabel("Actual Torque (Nm)", fontsize=PLOT_FONTS["label"])
    plt.ylabel("Predicted Torque (Nm)", fontsize=PLOT_FONTS["label"])
    plt.xticks(fontsize=PLOT_FONTS["tick"])
    plt.yticks(fontsize=PLOT_FONTS["tick"])
    plt.grid(alpha=0.35)
    plt.tight_layout()

    path = os.path.join(OUT_DIR_GRAPH, f"scatter_actual_vs_pred_{r}rpm.png")
    plt.savefig(path, dpi=PLOT_DPI)
    plt.close()

print(f"âœ… ëŒ€í‘œ RPM scatter ì €ì¥ ì™„ë£Œ: {OUT_DIR_GRAPH}/")


# ================================================================
# 14) ì˜ˆì¸¡ í•¨ìˆ˜ + ì˜ˆì¸¡ ì‹œë²”
# ================================================================
def predict_torque_curve(input_values_11, model, x_scaler, y_scaler, X_cols, device):
    """
    input_values_11: ê¸¸ì´ 11 ë¦¬ìŠ¤íŠ¸/ë°°ì—´ (X_cols ìˆœì„œëŒ€ë¡œ)
    return: torque curve length 18 (1000~18000rpm)
    """
    model.eval()
    arr = np.array(input_values_11).reshape(1, -1)

    # scaler feature-name warning ë°©ì§€
    inp_df = pd.DataFrame(arr, columns=X_cols)
    inp_s = x_scaler.transform(inp_df)

    inp_t = torch.tensor(inp_s, dtype=torch.float32, device=device)
    with torch.no_grad():
        pred_s = model(inp_t).detach().cpu().numpy()

    pred = y_scaler.inverse_transform(pred_s)[0]
    return pred


print("\n" + "=" * 60)
print("ğŸ¯ ì˜ˆì¸¡ ì‹œë²” (ë°ì´í„°ì…‹ ì²« ë²ˆì§¸ ìƒ˜í”Œ)")
print("=" * 60)

example_input = X_train_raw.iloc[0].values
torque_curve = predict_torque_curve(example_input, model, x_scaler, y_scaler, X_cols, device)

print("-" * 55)
print(f"{'RPM':>6s} | {'Torque (Nm)':>12s}")
print("-" * 55)
for i, rpm in enumerate(RPMS):
    print(f"{rpm:>6d} | {torque_curve[i]:>12.2f}")

np.savez(
    "machine/history_torque.npz",
    train_loss=np.array(history["train_loss"]),
    val_loss=np.array(history["val_loss"])
)
print("[OK] Saved: machine/history_torque.npz")

# 2) Validation prediction ì €ì¥ (parity / residual plotìš©)
np.savez(
    "machine/val_pred_torque.npz",
    y_true=y_test_raw.values.astype(np.float32),  # ë°˜ë“œì‹œ ì›ìŠ¤ì¼€ì¼
    y_pred=preds.astype(np.float32),             # inverse_transformëœ ê°’
    rpms=RPMS.astype(np.int32)
)
print("[OK] Saved: machine/val_pred_torque.npz")

# ================================================================
# 15) ìµœì¢… ëª¨ë¸ ì €ì¥
# ================================================================
final_path = os.path.join(OUT_DIR_MACHINE, "optimal_torque_model.pth")
torch.save(model.state_dict(), final_path)

print("\n" + "=" * 60)
print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
print("=" * 60)
print(f"âœ… ì €ì¥ ê²½ë¡œ: {final_path}")
print("ğŸ‰ ì™„ë£Œ!")
